{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from ethnicolr2 import pred_fl_last_name, pred_fl_full_name\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: \n",
    "\n",
    "https://github.com/appeler/ethnicolr2?tab=readme-ov-file\n",
    "\n",
    "https://github.com/appeler/ethnicolr_v2?tab=readme-ov-file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_single = pd.read_csv(\"./race_gender_data/df_single.csv\").iloc[:, 1:]\n",
    "df_others = pd.read_csv(\"./race_gender_data/df_others.csv\").iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./race_gender_data/df.csv\").iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>country</th>\n",
       "      <th>fullname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sabouni</td>\n",
       "      <td>manal</td>\n",
       "      <td>FR</td>\n",
       "      <td>sabouni manal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>claudia</td>\n",
       "      <td>perretta</td>\n",
       "      <td>UK</td>\n",
       "      <td>claudia perretta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yass</td>\n",
       "      <td>yass</td>\n",
       "      <td>CA</td>\n",
       "      <td>yass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tina</td>\n",
       "      <td>mccoy</td>\n",
       "      <td>US</td>\n",
       "      <td>tina mccoy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>whitney</td>\n",
       "      <td>reed</td>\n",
       "      <td>US</td>\n",
       "      <td>whitney reed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907993</th>\n",
       "      <td>tanya</td>\n",
       "      <td>ashworth</td>\n",
       "      <td>AU</td>\n",
       "      <td>tanya ashworth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907994</th>\n",
       "      <td>chris</td>\n",
       "      <td>kowalenko</td>\n",
       "      <td>UK</td>\n",
       "      <td>chris kowalenko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907995</th>\n",
       "      <td>faith</td>\n",
       "      <td>cummings</td>\n",
       "      <td>US</td>\n",
       "      <td>faith cummings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907996</th>\n",
       "      <td>karen</td>\n",
       "      <td>van</td>\n",
       "      <td>US</td>\n",
       "      <td>karen van</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907997</th>\n",
       "      <td>will</td>\n",
       "      <td>daley</td>\n",
       "      <td>UK</td>\n",
       "      <td>will daley</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1907998 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        firstname   lastname country          fullname\n",
       "0         sabouni      manal      FR     sabouni manal\n",
       "1         claudia   perretta      UK  claudia perretta\n",
       "2            yass       yass      CA              yass\n",
       "3            tina      mccoy      US        tina mccoy\n",
       "4         whitney       reed      US      whitney reed\n",
       "...           ...        ...     ...               ...\n",
       "1907993     tanya   ashworth      AU    tanya ashworth\n",
       "1907994     chris  kowalenko      UK   chris kowalenko\n",
       "1907995     faith   cummings      US    faith cummings\n",
       "1907996     karen        van      US         karen van\n",
       "1907997      will      daley      UK        will daley\n",
       "\n",
       "[1907998 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mshape, df_single\u001b[38;5;241m.\u001b[39mshape, df_others\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "print(df.shape, df_single.shape, df_others.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>country</th>\n",
       "      <th>fullname</th>\n",
       "      <th>pred_gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yass</td>\n",
       "      <td>yass</td>\n",
       "      <td>CA</td>\n",
       "      <td>yass</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zak</td>\n",
       "      <td>zak</td>\n",
       "      <td>UK</td>\n",
       "      <td>zak</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alyssa</td>\n",
       "      <td>alyssa</td>\n",
       "      <td>US</td>\n",
       "      <td>alyssa</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kyra</td>\n",
       "      <td>kyra</td>\n",
       "      <td>UK</td>\n",
       "      <td>kyra</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aftondivver</td>\n",
       "      <td>aftondivver</td>\n",
       "      <td>US</td>\n",
       "      <td>aftondivver</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65984</th>\n",
       "      <td>iturospee</td>\n",
       "      <td>iturospee</td>\n",
       "      <td>US</td>\n",
       "      <td>iturospee</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65985</th>\n",
       "      <td>hernatkova</td>\n",
       "      <td>hernatkova</td>\n",
       "      <td>US</td>\n",
       "      <td>hernatkova</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65986</th>\n",
       "      <td>dyce</td>\n",
       "      <td>dyce</td>\n",
       "      <td>US</td>\n",
       "      <td>dyce</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65987</th>\n",
       "      <td>jamal</td>\n",
       "      <td>jamal</td>\n",
       "      <td>DE</td>\n",
       "      <td>jamal</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65988</th>\n",
       "      <td>adil</td>\n",
       "      <td>adil</td>\n",
       "      <td>US</td>\n",
       "      <td>adil</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65989 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         firstname     lastname country     fullname pred_gender\n",
       "0             yass         yass      CA         yass      Female\n",
       "1              zak          zak      UK          zak      Female\n",
       "2           alyssa       alyssa      US       alyssa        Male\n",
       "3             kyra         kyra      UK         kyra      Female\n",
       "4      aftondivver  aftondivver      US  aftondivver        Male\n",
       "...            ...          ...     ...          ...         ...\n",
       "65984    iturospee    iturospee      US    iturospee        Male\n",
       "65985   hernatkova   hernatkova      US   hernatkova      Female\n",
       "65986         dyce         dyce      US         dyce      Female\n",
       "65987        jamal        jamal      DE        jamal        Male\n",
       "65988         adil         adil      US         adil        Male\n",
       "\n",
       "[65989 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>country</th>\n",
       "      <th>fullname</th>\n",
       "      <th>pred_gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sabouni</td>\n",
       "      <td>manal</td>\n",
       "      <td>FR</td>\n",
       "      <td>sabouni manal</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>claudia</td>\n",
       "      <td>perretta</td>\n",
       "      <td>UK</td>\n",
       "      <td>claudia perretta</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tina</td>\n",
       "      <td>mccoy</td>\n",
       "      <td>US</td>\n",
       "      <td>tina mccoy</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>whitney</td>\n",
       "      <td>reed</td>\n",
       "      <td>US</td>\n",
       "      <td>whitney reed</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>leonora</td>\n",
       "      <td>camovic</td>\n",
       "      <td>US</td>\n",
       "      <td>leonora camovic</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646836</th>\n",
       "      <td>tanya</td>\n",
       "      <td>ashworth</td>\n",
       "      <td>AU</td>\n",
       "      <td>tanya ashworth</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646837</th>\n",
       "      <td>chris</td>\n",
       "      <td>kowalenko</td>\n",
       "      <td>UK</td>\n",
       "      <td>chris kowalenko</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646838</th>\n",
       "      <td>faith</td>\n",
       "      <td>cummings</td>\n",
       "      <td>US</td>\n",
       "      <td>faith cummings</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646839</th>\n",
       "      <td>karen</td>\n",
       "      <td>van</td>\n",
       "      <td>US</td>\n",
       "      <td>karen van</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646840</th>\n",
       "      <td>will</td>\n",
       "      <td>daley</td>\n",
       "      <td>UK</td>\n",
       "      <td>will daley</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1646841 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        firstname   lastname country          fullname pred_gender\n",
       "0         sabouni      manal      FR     sabouni manal        Male\n",
       "1         claudia   perretta      UK  claudia perretta      Female\n",
       "2            tina      mccoy      US        tina mccoy      Female\n",
       "3         whitney       reed      US      whitney reed      Female\n",
       "4         leonora    camovic      US   leonora camovic      Female\n",
       "...           ...        ...     ...               ...         ...\n",
       "1646836     tanya   ashworth      AU    tanya ashworth      Female\n",
       "1646837     chris  kowalenko      UK   chris kowalenko        Male\n",
       "1646838     faith   cummings      US    faith cummings      Female\n",
       "1646839     karen        van      US         karen van      Female\n",
       "1646840      will      daley      UK        will daley        Male\n",
       "\n",
       "[1646841 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>country</th>\n",
       "      <th>fullname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sabouni</td>\n",
       "      <td>manal</td>\n",
       "      <td>FR</td>\n",
       "      <td>sabouni manal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>claudia</td>\n",
       "      <td>perretta</td>\n",
       "      <td>UK</td>\n",
       "      <td>claudia perretta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yass</td>\n",
       "      <td>yass</td>\n",
       "      <td>CA</td>\n",
       "      <td>yass yass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tina</td>\n",
       "      <td>mccoy</td>\n",
       "      <td>US</td>\n",
       "      <td>tina mccoy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>whitney</td>\n",
       "      <td>reed</td>\n",
       "      <td>US</td>\n",
       "      <td>whitney reed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907993</th>\n",
       "      <td>tanya</td>\n",
       "      <td>ashworth</td>\n",
       "      <td>AU</td>\n",
       "      <td>tanya ashworth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907994</th>\n",
       "      <td>chris</td>\n",
       "      <td>kowalenko</td>\n",
       "      <td>UK</td>\n",
       "      <td>chris kowalenko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907995</th>\n",
       "      <td>faith</td>\n",
       "      <td>cummings</td>\n",
       "      <td>US</td>\n",
       "      <td>faith cummings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907996</th>\n",
       "      <td>karen</td>\n",
       "      <td>van</td>\n",
       "      <td>US</td>\n",
       "      <td>karen van</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907997</th>\n",
       "      <td>will</td>\n",
       "      <td>daley</td>\n",
       "      <td>UK</td>\n",
       "      <td>will daley</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1907998 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        firstname   lastname country          fullname\n",
       "0         sabouni      manal      FR     sabouni manal\n",
       "1         claudia   perretta      UK  claudia perretta\n",
       "2            yass       yass      CA         yass yass\n",
       "3            tina      mccoy      US        tina mccoy\n",
       "4         whitney       reed      US      whitney reed\n",
       "...           ...        ...     ...               ...\n",
       "1907993     tanya   ashworth      AU    tanya ashworth\n",
       "1907994     chris  kowalenko      UK   chris kowalenko\n",
       "1907995     faith   cummings      US    faith cummings\n",
       "1907996     karen        van      US         karen van\n",
       "1907997      will      daley      UK        will daley\n",
       "\n",
       "[1907998 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries with Unknown predicted gender:\n",
      "Empty DataFrame\n",
      "Columns: [firstname, lastname, country, fullname, pred_gender]\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>country</th>\n",
       "      <th>fullname</th>\n",
       "      <th>pred_gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sabouni</td>\n",
       "      <td>manal</td>\n",
       "      <td>FR</td>\n",
       "      <td>sabouni manal</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>claudia</td>\n",
       "      <td>perretta</td>\n",
       "      <td>UK</td>\n",
       "      <td>claudia perretta</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yass</td>\n",
       "      <td>yass</td>\n",
       "      <td>CA</td>\n",
       "      <td>yass</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tina</td>\n",
       "      <td>mccoy</td>\n",
       "      <td>US</td>\n",
       "      <td>tina mccoy</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>whitney</td>\n",
       "      <td>reed</td>\n",
       "      <td>US</td>\n",
       "      <td>whitney reed</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712825</th>\n",
       "      <td>tanya</td>\n",
       "      <td>ashworth</td>\n",
       "      <td>AU</td>\n",
       "      <td>tanya ashworth</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712826</th>\n",
       "      <td>chris</td>\n",
       "      <td>kowalenko</td>\n",
       "      <td>UK</td>\n",
       "      <td>chris kowalenko</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712827</th>\n",
       "      <td>faith</td>\n",
       "      <td>cummings</td>\n",
       "      <td>US</td>\n",
       "      <td>faith cummings</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712828</th>\n",
       "      <td>karen</td>\n",
       "      <td>van</td>\n",
       "      <td>US</td>\n",
       "      <td>karen van</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712829</th>\n",
       "      <td>will</td>\n",
       "      <td>daley</td>\n",
       "      <td>UK</td>\n",
       "      <td>will daley</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1712830 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        firstname   lastname country          fullname pred_gender\n",
       "0         sabouni      manal      FR     sabouni manal        Male\n",
       "1         claudia   perretta      UK  claudia perretta      Female\n",
       "2            yass       yass      CA              yass      Female\n",
       "3            tina      mccoy      US        tina mccoy      Female\n",
       "4         whitney       reed      US      whitney reed      Female\n",
       "...           ...        ...     ...               ...         ...\n",
       "1712825     tanya   ashworth      AU    tanya ashworth      Female\n",
       "1712826     chris  kowalenko      UK   chris kowalenko        Male\n",
       "1712827     faith   cummings      US    faith cummings      Female\n",
       "1712828     karen        van      US         karen van      Female\n",
       "1712829      will      daley      UK        will daley        Male\n",
       "\n",
       "[1712830 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gender = pd.read_csv(\"./race_gender_data/df_gender.csv\")\n",
    "unknown_entries = df_gender[df_gender[\"pred_gender\"] == \"Unknown\"]\n",
    "print(\"Entries with Unknown predicted gender:\")\n",
    "print(unknown_entries)\n",
    "df_gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>country</th>\n",
       "      <th>fullname</th>\n",
       "      <th>pred_gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sabouni</td>\n",
       "      <td>manal</td>\n",
       "      <td>FR</td>\n",
       "      <td>sabouni manal</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>claudia</td>\n",
       "      <td>perretta</td>\n",
       "      <td>UK</td>\n",
       "      <td>claudia perretta</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tina</td>\n",
       "      <td>mccoy</td>\n",
       "      <td>US</td>\n",
       "      <td>tina mccoy</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>whitney</td>\n",
       "      <td>reed</td>\n",
       "      <td>US</td>\n",
       "      <td>whitney reed</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>leonora</td>\n",
       "      <td>camovic</td>\n",
       "      <td>US</td>\n",
       "      <td>leonora camovic</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646836</th>\n",
       "      <td>tanya</td>\n",
       "      <td>ashworth</td>\n",
       "      <td>AU</td>\n",
       "      <td>tanya ashworth</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646837</th>\n",
       "      <td>chris</td>\n",
       "      <td>kowalenko</td>\n",
       "      <td>UK</td>\n",
       "      <td>chris kowalenko</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646838</th>\n",
       "      <td>faith</td>\n",
       "      <td>cummings</td>\n",
       "      <td>US</td>\n",
       "      <td>faith cummings</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646839</th>\n",
       "      <td>karen</td>\n",
       "      <td>van</td>\n",
       "      <td>US</td>\n",
       "      <td>karen van</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646840</th>\n",
       "      <td>will</td>\n",
       "      <td>daley</td>\n",
       "      <td>UK</td>\n",
       "      <td>will daley</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1646841 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        firstname   lastname country          fullname pred_gender\n",
       "0         sabouni      manal      FR     sabouni manal        Male\n",
       "1         claudia   perretta      UK  claudia perretta      Female\n",
       "2            tina      mccoy      US        tina mccoy      Female\n",
       "3         whitney       reed      US      whitney reed      Female\n",
       "4         leonora    camovic      US   leonora camovic      Female\n",
       "...           ...        ...     ...               ...         ...\n",
       "1646836     tanya   ashworth      AU    tanya ashworth      Female\n",
       "1646837     chris  kowalenko      UK   chris kowalenko        Male\n",
       "1646838     faith   cummings      US    faith cummings      Female\n",
       "1646839     karen        van      US         karen van      Female\n",
       "1646840      will      daley      UK        will daley        Male\n",
       "\n",
       "[1646841 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fullname+df_others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>country</th>\n",
       "      <th>fullname</th>\n",
       "      <th>pred_gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>sabouni</td>\n",
       "      <td>manal</td>\n",
       "      <td>FR</td>\n",
       "      <td>sabouni manal</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>claudia</td>\n",
       "      <td>perretta</td>\n",
       "      <td>UK</td>\n",
       "      <td>claudia perretta</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tina</td>\n",
       "      <td>mccoy</td>\n",
       "      <td>US</td>\n",
       "      <td>tina mccoy</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>whitney</td>\n",
       "      <td>reed</td>\n",
       "      <td>US</td>\n",
       "      <td>whitney reed</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>leonora</td>\n",
       "      <td>camovic</td>\n",
       "      <td>US</td>\n",
       "      <td>leonora camovic</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646836</th>\n",
       "      <td>1646836</td>\n",
       "      <td>tanya</td>\n",
       "      <td>ashworth</td>\n",
       "      <td>AU</td>\n",
       "      <td>tanya ashworth</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646837</th>\n",
       "      <td>1646837</td>\n",
       "      <td>chris</td>\n",
       "      <td>kowalenko</td>\n",
       "      <td>UK</td>\n",
       "      <td>chris kowalenko</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646838</th>\n",
       "      <td>1646838</td>\n",
       "      <td>faith</td>\n",
       "      <td>cummings</td>\n",
       "      <td>US</td>\n",
       "      <td>faith cummings</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646839</th>\n",
       "      <td>1646839</td>\n",
       "      <td>karen</td>\n",
       "      <td>van</td>\n",
       "      <td>US</td>\n",
       "      <td>karen van</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646840</th>\n",
       "      <td>1646840</td>\n",
       "      <td>will</td>\n",
       "      <td>daley</td>\n",
       "      <td>UK</td>\n",
       "      <td>will daley</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1646841 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0 firstname   lastname country          fullname pred_gender\n",
       "0                 0   sabouni      manal      FR     sabouni manal        Male\n",
       "1                 1   claudia   perretta      UK  claudia perretta      Female\n",
       "2                 2      tina      mccoy      US        tina mccoy      Female\n",
       "3                 3   whitney       reed      US      whitney reed      Female\n",
       "4                 4   leonora    camovic      US   leonora camovic      Female\n",
       "...             ...       ...        ...     ...               ...         ...\n",
       "1646836     1646836     tanya   ashworth      AU    tanya ashworth      Female\n",
       "1646837     1646837     chris  kowalenko      UK   chris kowalenko        Male\n",
       "1646838     1646838     faith   cummings      US    faith cummings      Female\n",
       "1646839     1646839     karen        van      US         karen van      Female\n",
       "1646840     1646840      will      daley      UK        will daley        Male\n",
       "\n",
       "[1646841 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_others = pd.read_csv(\"./race_gender_data/df_others.csv\")\n",
    "df_others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test with chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save chunk csv files - works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_in_chunks(df, chunk_size):\n",
    "    results = []\n",
    "    for start in range(0, len(df), chunk_size):\n",
    "        end = min(start + chunk_size, len(df))\n",
    "        chunk = df.iloc[start:end]\n",
    "\n",
    "        # Run prediction on the chunk\n",
    "        pred_chunk = pred_fl_full_name(\n",
    "            chunk, lname_col=\"lastname\", fname_col=\"firstname\"\n",
    "        )\n",
    "\n",
    "        # Save the current chunk to a CSV file\n",
    "        chunk_number = start // chunk_size + 1\n",
    "        pred_chunk.to_csv(\n",
    "            f\"./race_gender_data/df_others_chunk_{chunk_number}.csv\", index=False\n",
    "        )\n",
    "    print(f\"Processed chunk from {start} to {end}\")\n",
    "\n",
    "\n",
    "pred_with_fullname = process_in_chunks(df_others, chunk_size=500000)\n",
    "pred_with_fullname.to_csv(\"./race_gender_data/race_gender_full_others.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to process in chunks\n",
    "def process_in_chunks(df, chunk_size):\n",
    "    results = []\n",
    "    for start in range(0, len(df), chunk_size):\n",
    "        end = min(start + chunk_size, len(df))\n",
    "        chunk = df.iloc[start:end]\n",
    "\n",
    "        # Run prediction on the chunk\n",
    "        pred_chunk = pred_fl_full_name(\n",
    "            chunk, lname_col=\"lastname\", fname_col=\"firstname\"\n",
    "        )\n",
    "        results.append(pred_chunk)\n",
    "\n",
    "    # Concatenate all results\n",
    "    return pd.concat(results, ignore_index=True)\n",
    "    print(f\"Processed chunk from {start} to {end}\")\n",
    "\n",
    "\n",
    "# Process df_others in chunks of 1000 rows\n",
    "pred_with_fullname = process_in_chunks(df_others, chunk_size=500000)\n",
    "\n",
    "# Save the concatenated results to CSV\n",
    "pred_with_fullname.to_csv(\"./race_gender_data/race_gender_full_others.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7813/7813 [03:49<00:00, 34.08it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_with_fullname = pred_fl_full_name(\n",
    "    df_others[:500000], lname_col=\"lastname\", fname_col=\"firstname\"\n",
    ")\n",
    "pred_with_fullname.to_csv(\"./race_gender_data/race_gender_full_others.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 28/10107 [00:00<03:31, 47.74it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred_with_fullname \u001b[38;5;241m=\u001b[39m \u001b[43mpred_fl_full_name\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf_others\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1000000\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlname_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlastname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfirstname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m pred_with_fullname\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./race_gender_data/df_other_chunk_3.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/jc/lib/python3.11/site-packages/ethnicolr2/pred_fl_fn_lstm.py:47\u001b[0m, in \u001b[0;36mFullNameLstmModel.pred_fl_full_name\u001b[0;34m(cls, df, full_name_col, lname_col, fname_col)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[full_name_col]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mtitle()\n\u001b[0;32m---> 47\u001b[0m rdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVOCAB_FN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL_FN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m rdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__name\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rdf\n",
      "File \u001b[0;32m~/anaconda3/envs/jc/lib/python3.11/site-packages/ethnicolr2/ethnicolr_class.py:112\u001b[0m, in \u001b[0;36mEthnicolrModelClass.predict\u001b[0;34m(cls, df, vocab_fn, model_fn)\u001b[0m\n\u001b[1;32m    110\u001b[0m tns \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# Compute the predictions\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# get soft probabilities\u001b[39;00m\n\u001b[1;32m    114\u001b[0m probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/jc/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/jc/lib/python3.11/site-packages/ethnicolr2/models.py:17\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m---> 17\u001b[0m     embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIntTensor\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     h0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, embedded\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     19\u001b[0m     c0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, embedded\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/anaconda3/envs/jc/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/jc/lib/python3.11/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/jc/lib/python3.11/site-packages/torch/nn/functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2205\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2206\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "pred_with_fullname = pred_fl_full_name(\n",
    "    df_others[1000000:], lname_col=\"lastname\", fname_col=\"firstname\"\n",
    ")\n",
    "pred_with_fullname.to_csv(\"./race_gender_data/df_other_chunk_3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lastname +df_single\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read df_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>country</th>\n",
       "      <th>fullname</th>\n",
       "      <th>pred_gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>yass</td>\n",
       "      <td>yass</td>\n",
       "      <td>CA</td>\n",
       "      <td>yass</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>zak</td>\n",
       "      <td>zak</td>\n",
       "      <td>UK</td>\n",
       "      <td>zak</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>alyssa</td>\n",
       "      <td>alyssa</td>\n",
       "      <td>US</td>\n",
       "      <td>alyssa</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>kyra</td>\n",
       "      <td>kyra</td>\n",
       "      <td>UK</td>\n",
       "      <td>kyra</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>aftondivver</td>\n",
       "      <td>aftondivver</td>\n",
       "      <td>US</td>\n",
       "      <td>aftondivver</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65984</th>\n",
       "      <td>65984</td>\n",
       "      <td>iturospee</td>\n",
       "      <td>iturospee</td>\n",
       "      <td>US</td>\n",
       "      <td>iturospee</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65985</th>\n",
       "      <td>65985</td>\n",
       "      <td>hernatkova</td>\n",
       "      <td>hernatkova</td>\n",
       "      <td>US</td>\n",
       "      <td>hernatkova</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65986</th>\n",
       "      <td>65986</td>\n",
       "      <td>dyce</td>\n",
       "      <td>dyce</td>\n",
       "      <td>US</td>\n",
       "      <td>dyce</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65987</th>\n",
       "      <td>65987</td>\n",
       "      <td>jamal</td>\n",
       "      <td>jamal</td>\n",
       "      <td>DE</td>\n",
       "      <td>jamal</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65988</th>\n",
       "      <td>65988</td>\n",
       "      <td>adil</td>\n",
       "      <td>adil</td>\n",
       "      <td>US</td>\n",
       "      <td>adil</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65989 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0    firstname     lastname country     fullname pred_gender\n",
       "0               0         yass         yass      CA         yass      Female\n",
       "1               1          zak          zak      UK          zak      Female\n",
       "2               2       alyssa       alyssa      US       alyssa        Male\n",
       "3               3         kyra         kyra      UK         kyra      Female\n",
       "4               4  aftondivver  aftondivver      US  aftondivver        Male\n",
       "...           ...          ...          ...     ...          ...         ...\n",
       "65984       65984    iturospee    iturospee      US    iturospee        Male\n",
       "65985       65985   hernatkova   hernatkova      US   hernatkova      Female\n",
       "65986       65986         dyce         dyce      US         dyce      Female\n",
       "65987       65987        jamal        jamal      DE        jamal        Male\n",
       "65988       65988         adil         adil      US         adil        Male\n",
       "\n",
       "[65989 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_single = pd.read_csv(\"./race_gender_data/df_single.csv\")\n",
    "df_single"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test with chunk, df_others+df_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to process in chunks\n",
    "def process_in_chunks(\n",
    "    df, chunk_size, prediction_function, lname_col=None, fname_col=None\n",
    "):\n",
    "    results = []\n",
    "    for start in range(0, len(df), chunk_size):\n",
    "        end = min(start + chunk_size, len(df))\n",
    "        chunk = df.iloc[start:end]\n",
    "\n",
    "        # Run prediction on the chunk\n",
    "        if prediction_function == pred_fl_full_name:\n",
    "            pred_chunk = prediction_function(\n",
    "                chunk, lname_col=lname_col, fname_col=fname_col\n",
    "            )\n",
    "        elif prediction_function == pred_fl_last_name:\n",
    "            pred_chunk = prediction_function(chunk, lname_col=lname_col)\n",
    "\n",
    "        results.append(pred_chunk)\n",
    "\n",
    "    # Concatenate all results\n",
    "    return pd.concat(results, ignore_index=True)\n",
    "    print(f\"Processed chunk from {start} to {end}\")\n",
    "\n",
    "\n",
    "# Process df_others in chunks of 1000 rows\n",
    "pred_with_fullname = process_in_chunks(\n",
    "    df_others,\n",
    "    chunk_size=100000,\n",
    "    prediction_function=pred_fl_full_name,\n",
    "    lname_col=\"lastname\",\n",
    "    fname_col=\"firstname\",\n",
    ")\n",
    "\n",
    "# Save the concatenated results to CSV\n",
    "pred_with_fullname.to_csv(\"./race_gender_data/race_gender_full_others.csv\", index=False)\n",
    "\n",
    "# Process df_single in chunks for last name prediction\n",
    "pred_with_lastname = process_in_chunks(\n",
    "    df_single,\n",
    "    chunk_size=5000,\n",
    "    prediction_function=pred_fl_last_name,\n",
    "    lname_col=\"lastname\",\n",
    ")\n",
    "pred_with_lastname.to_csv(\"./race_gender_data/race_gender_last_single.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save chunk csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 35.09it/s]\n",
      "100%|██████████| 157/157 [00:04<00:00, 35.59it/s]\n",
      " 67%|██████▋   | 105/157 [00:02<00:01, 35.88it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Concatenate all results\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mconcat(results, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 23\u001b[0m pred_fl_last_name \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_in_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_single\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m pred_fl_last_name\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./race_gender_data/race_gender_last_.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[20], line 8\u001b[0m, in \u001b[0;36mprocess_in_chunks\u001b[0;34m(df, chunk_size)\u001b[0m\n\u001b[1;32m      5\u001b[0m chunk \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[start:end]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Run prediction on the chunk\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m pred_chunk \u001b[38;5;241m=\u001b[39m \u001b[43mpred_fl_full_name\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlname_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlastname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfirstname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(pred_chunk)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Save the current chunk to a CSV file\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/jc/lib/python3.11/site-packages/ethnicolr2/pred_fl_fn_lstm.py:47\u001b[0m, in \u001b[0;36mFullNameLstmModel.pred_fl_full_name\u001b[0;34m(cls, df, full_name_col, lname_col, fname_col)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[full_name_col]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mtitle()\n\u001b[0;32m---> 47\u001b[0m rdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVOCAB_FN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL_FN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m rdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__name\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rdf\n",
      "File \u001b[0;32m~/anaconda3/envs/jc/lib/python3.11/site-packages/ethnicolr2/ethnicolr_class.py:112\u001b[0m, in \u001b[0;36mEthnicolrModelClass.predict\u001b[0;34m(cls, df, vocab_fn, model_fn)\u001b[0m\n\u001b[1;32m    110\u001b[0m tns \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# Compute the predictions\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# get soft probabilities\u001b[39;00m\n\u001b[1;32m    114\u001b[0m probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/jc/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/jc/lib/python3.11/site-packages/ethnicolr2/models.py:17\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m---> 17\u001b[0m     embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIntTensor\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     h0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, embedded\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     19\u001b[0m     c0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, embedded\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/anaconda3/envs/jc/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/jc/lib/python3.11/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/jc/lib/python3.11/site-packages/torch/nn/functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2205\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2206\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "# Define a function to process the dataframe in chunks and save each chunk\n",
    "def process_in_chunks_lastname(df, chunk_size):\n",
    "    results = []\n",
    "    for start in range(0, len(df), chunk_size):\n",
    "        end = min(start + chunk_size, len(df))\n",
    "        chunk = df.iloc[start:end]\n",
    "\n",
    "        # Run prediction on the chunk\n",
    "        pred_chunk = pred_fl_last_name(chunk, lname_col=\"lastname\")\n",
    "        results.append(pred_chunk)\n",
    "\n",
    "        # Save the current chunk to a CSV file\n",
    "        chunk_number = start // chunk_size + 1\n",
    "        pred_chunk.to_csv(\n",
    "            f\"./race_gender_data/df_single_chunk_{chunk_number}.csv\", index=False\n",
    "        )\n",
    "        print(f\"Processed chunk from {start} to {end}\")\n",
    "\n",
    "    # Concatenate all results\n",
    "    return pd.concat(results, ignore_index=True)\n",
    "\n",
    "\n",
    "pred_fl_last_name = process_in_chunks(df_single, chunk_size=10000)\n",
    "pred_fl_last_name.to_csv(\"./race_gender_data/race_gender_last_.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last</th>\n",
       "      <th>first</th>\n",
       "      <th>true_race</th>\n",
       "      <th>preds</th>\n",
       "      <th>probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yass</td>\n",
       "      <td>yass yass</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.039757933, 'hispanic': 0.39860517,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>raul</td>\n",
       "      <td>raul</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.017201504, 'hispanic': 0.023858989...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xx</td>\n",
       "      <td>xx</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.012569758, 'hispanic': 0.026675707...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X</td>\n",
       "      <td>RoneDanielFastFloBgi</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>asian</td>\n",
       "      <td>{'asian': 0.70105106, 'hispanic': 0.02619504, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   last                 first true_race     preds  \\\n",
       "0  yass             yass yass  nh_white  nh_white   \n",
       "1  raul                  raul  hispanic  nh_white   \n",
       "2    xx                    xx  hispanic  nh_white   \n",
       "3     X  RoneDanielFastFloBgi  hispanic     asian   \n",
       "\n",
       "                                               probs  \n",
       "0  {'asian': 0.039757933, 'hispanic': 0.39860517,...  \n",
       "1  {'asian': 0.017201504, 'hispanic': 0.023858989...  \n",
       "2  {'asian': 0.012569758, 'hispanic': 0.026675707...  \n",
       "3  {'asian': 0.70105106, 'hispanic': 0.02619504, ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_fl_last_name(df_single, lname_col=\"lastname\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat chunk files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated 4 files into ./race_gender_data/df_others_race_gender.csv\n",
      "Concatenated 7 files into ./race_gender_data/df_single_race_gender.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "\n",
    "# Concatenate all df_others chunks\n",
    "def concat_chunks(file_pattern, output_file):\n",
    "    # Use glob to match the file pattern and load all matching files\n",
    "    chunk_files = glob.glob(file_pattern)\n",
    "\n",
    "    # Concatenate all chunks\n",
    "    df_combined = pd.concat(\n",
    "        [pd.read_csv(file) for file in chunk_files], ignore_index=True\n",
    "    )\n",
    "\n",
    "    # Save the combined dataframe to a new CSV file\n",
    "    df_combined.to_csv(output_file, index=False)\n",
    "    print(f\"Concatenated {len(chunk_files)} files into {output_file}\")\n",
    "\n",
    "\n",
    "# Concatenate df_others chunks\n",
    "concat_chunks(\n",
    "    \"./race_gender_data/df_others_chunk_*.csv\",\n",
    "    \"./race_gender_data/df_others_race_gender.csv\",\n",
    ")\n",
    "\n",
    "# Concatenate df_single chunks\n",
    "concat_chunks(\n",
    "    \"./race_gender_data/df_single_chunk_*.csv\",\n",
    "    \"./race_gender_data/df_single_race_gender.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean race_gender_last_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>country</th>\n",
       "      <th>fullname</th>\n",
       "      <th>pred_gender</th>\n",
       "      <th>preds</th>\n",
       "      <th>probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yass</td>\n",
       "      <td>yass</td>\n",
       "      <td>CA</td>\n",
       "      <td>yass</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.039757933, 'hispanic': 0.39860517,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zak</td>\n",
       "      <td>zak</td>\n",
       "      <td>UK</td>\n",
       "      <td>zak</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.022933554, 'hispanic': 0.020127507...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zak</td>\n",
       "      <td>zak</td>\n",
       "      <td>UK</td>\n",
       "      <td>zak</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.022933554, 'hispanic': 0.020127507...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zak</td>\n",
       "      <td>zak</td>\n",
       "      <td>UK</td>\n",
       "      <td>zak</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.022933554, 'hispanic': 0.020127507...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alyssa</td>\n",
       "      <td>alyssa</td>\n",
       "      <td>US</td>\n",
       "      <td>alyssa</td>\n",
       "      <td>Male</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.029911637, 'hispanic': 0.1969176, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78764</th>\n",
       "      <td>fregouville</td>\n",
       "      <td>fregouville</td>\n",
       "      <td>FR</td>\n",
       "      <td>fregouville</td>\n",
       "      <td>Male</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.004903849, 'hispanic': 0.067926176...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78765</th>\n",
       "      <td>msahli</td>\n",
       "      <td>msahli</td>\n",
       "      <td>FR</td>\n",
       "      <td>msahli</td>\n",
       "      <td>Male</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.07436386, 'hispanic': 0.049667317,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78766</th>\n",
       "      <td>boccheciampe</td>\n",
       "      <td>boccheciampe</td>\n",
       "      <td>FR</td>\n",
       "      <td>boccheciampe</td>\n",
       "      <td>Female</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>{'asian': 0.023130896, 'hispanic': 0.77701527,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78767</th>\n",
       "      <td>jordpulkownik</td>\n",
       "      <td>jordpulkownik</td>\n",
       "      <td>US</td>\n",
       "      <td>jordpulkownik</td>\n",
       "      <td>Male</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.0054982407, 'hispanic': 0.03553804...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78768</th>\n",
       "      <td>salymar</td>\n",
       "      <td>salymar</td>\n",
       "      <td>MX</td>\n",
       "      <td>salymar</td>\n",
       "      <td>Male</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.02226789, 'hispanic': 0.039258894,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78769 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           firstname       lastname country       fullname pred_gender  \\\n",
       "0               yass           yass      CA           yass      Female   \n",
       "1                zak            zak      UK            zak      Female   \n",
       "2                zak            zak      UK            zak      Female   \n",
       "3                zak            zak      UK            zak      Female   \n",
       "4             alyssa         alyssa      US         alyssa        Male   \n",
       "...              ...            ...     ...            ...         ...   \n",
       "78764    fregouville    fregouville      FR    fregouville        Male   \n",
       "78765         msahli         msahli      FR         msahli        Male   \n",
       "78766   boccheciampe   boccheciampe      FR   boccheciampe      Female   \n",
       "78767  jordpulkownik  jordpulkownik      US  jordpulkownik        Male   \n",
       "78768        salymar        salymar      MX        salymar        Male   \n",
       "\n",
       "          preds                                              probs  \n",
       "0      nh_white  {'asian': 0.039757933, 'hispanic': 0.39860517,...  \n",
       "1      nh_white  {'asian': 0.022933554, 'hispanic': 0.020127507...  \n",
       "2      nh_white  {'asian': 0.022933554, 'hispanic': 0.020127507...  \n",
       "3      nh_white  {'asian': 0.022933554, 'hispanic': 0.020127507...  \n",
       "4      nh_white  {'asian': 0.029911637, 'hispanic': 0.1969176, ...  \n",
       "...         ...                                                ...  \n",
       "78764  nh_white  {'asian': 0.004903849, 'hispanic': 0.067926176...  \n",
       "78765  nh_white  {'asian': 0.07436386, 'hispanic': 0.049667317,...  \n",
       "78766  hispanic  {'asian': 0.023130896, 'hispanic': 0.77701527,...  \n",
       "78767  nh_white  {'asian': 0.0054982407, 'hispanic': 0.03553804...  \n",
       "78768  nh_white  {'asian': 0.02226789, 'hispanic': 0.039258894,...  \n",
       "\n",
       "[78769 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_gender_last_single = pd.read_csv(\"./race_gender_data/df_single_race_gender.csv\")\n",
    "# # remove the last column\n",
    "# race_gender_last_single = race_gender_last_single.iloc[:, :-1]\n",
    "race_gender_last_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>country</th>\n",
       "      <th>fullname</th>\n",
       "      <th>pred_gender</th>\n",
       "      <th>preds</th>\n",
       "      <th>probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yass</td>\n",
       "      <td>yass</td>\n",
       "      <td>CA</td>\n",
       "      <td>yass</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.039757933, 'hispanic': 0.39860517,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zak</td>\n",
       "      <td>zak</td>\n",
       "      <td>UK</td>\n",
       "      <td>zak</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.022933554, 'hispanic': 0.020127507...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alyssa</td>\n",
       "      <td>alyssa</td>\n",
       "      <td>US</td>\n",
       "      <td>alyssa</td>\n",
       "      <td>Male</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.029911637, 'hispanic': 0.1969176, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kyra</td>\n",
       "      <td>kyra</td>\n",
       "      <td>UK</td>\n",
       "      <td>kyra</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.029823758, 'hispanic': 0.016653847...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>aftondivver</td>\n",
       "      <td>aftondivver</td>\n",
       "      <td>US</td>\n",
       "      <td>aftondivver</td>\n",
       "      <td>Male</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.015394655, 'hispanic': 0.040740304...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78764</th>\n",
       "      <td>fregouville</td>\n",
       "      <td>fregouville</td>\n",
       "      <td>FR</td>\n",
       "      <td>fregouville</td>\n",
       "      <td>Male</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.004903849, 'hispanic': 0.067926176...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78765</th>\n",
       "      <td>msahli</td>\n",
       "      <td>msahli</td>\n",
       "      <td>FR</td>\n",
       "      <td>msahli</td>\n",
       "      <td>Male</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.07436386, 'hispanic': 0.049667317,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78766</th>\n",
       "      <td>boccheciampe</td>\n",
       "      <td>boccheciampe</td>\n",
       "      <td>FR</td>\n",
       "      <td>boccheciampe</td>\n",
       "      <td>Female</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>{'asian': 0.023130896, 'hispanic': 0.77701527,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78767</th>\n",
       "      <td>jordpulkownik</td>\n",
       "      <td>jordpulkownik</td>\n",
       "      <td>US</td>\n",
       "      <td>jordpulkownik</td>\n",
       "      <td>Male</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.0054982407, 'hispanic': 0.03553804...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78768</th>\n",
       "      <td>salymar</td>\n",
       "      <td>salymar</td>\n",
       "      <td>MX</td>\n",
       "      <td>salymar</td>\n",
       "      <td>Male</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.02226789, 'hispanic': 0.039258894,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65987 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           firstname       lastname country       fullname pred_gender  \\\n",
       "0               yass           yass      CA           yass      Female   \n",
       "1                zak            zak      UK            zak      Female   \n",
       "4             alyssa         alyssa      US         alyssa        Male   \n",
       "6               kyra           kyra      UK           kyra      Female   \n",
       "10       aftondivver    aftondivver      US    aftondivver        Male   \n",
       "...              ...            ...     ...            ...         ...   \n",
       "78764    fregouville    fregouville      FR    fregouville        Male   \n",
       "78765         msahli         msahli      FR         msahli        Male   \n",
       "78766   boccheciampe   boccheciampe      FR   boccheciampe      Female   \n",
       "78767  jordpulkownik  jordpulkownik      US  jordpulkownik        Male   \n",
       "78768        salymar        salymar      MX        salymar        Male   \n",
       "\n",
       "          preds                                              probs  \n",
       "0      nh_white  {'asian': 0.039757933, 'hispanic': 0.39860517,...  \n",
       "1      nh_white  {'asian': 0.022933554, 'hispanic': 0.020127507...  \n",
       "4      nh_white  {'asian': 0.029911637, 'hispanic': 0.1969176, ...  \n",
       "6      nh_white  {'asian': 0.029823758, 'hispanic': 0.016653847...  \n",
       "10     nh_white  {'asian': 0.015394655, 'hispanic': 0.040740304...  \n",
       "...         ...                                                ...  \n",
       "78764  nh_white  {'asian': 0.004903849, 'hispanic': 0.067926176...  \n",
       "78765  nh_white  {'asian': 0.07436386, 'hispanic': 0.049667317,...  \n",
       "78766  hispanic  {'asian': 0.023130896, 'hispanic': 0.77701527,...  \n",
       "78767  nh_white  {'asian': 0.0054982407, 'hispanic': 0.03553804...  \n",
       "78768  nh_white  {'asian': 0.02226789, 'hispanic': 0.039258894,...  \n",
       "\n",
       "[65987 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_gender_last_single = race_gender_last_single.dropna()\n",
    "race_gender_last_single = race_gender_last_single.drop_duplicates()\n",
    "race_gender_last_single"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean race_gender_full_others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_gender_full_others = pd.read_csv(\"./race_gender_data/df_others_race_gender.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>country</th>\n",
       "      <th>fullname</th>\n",
       "      <th>pred_gender</th>\n",
       "      <th>preds</th>\n",
       "      <th>probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sabouni</td>\n",
       "      <td>manal</td>\n",
       "      <td>FR</td>\n",
       "      <td>sabouni manal</td>\n",
       "      <td>Male</td>\n",
       "      <td>nh_black</td>\n",
       "      <td>{'asian': 0.090085596, 'hispanic': 0.011093363...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>claudia</td>\n",
       "      <td>perretta</td>\n",
       "      <td>UK</td>\n",
       "      <td>claudia perretta</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.0024087005, 'hispanic': 0.23162283...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tina</td>\n",
       "      <td>mccoy</td>\n",
       "      <td>US</td>\n",
       "      <td>tina mccoy</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.0040824614, 'hispanic': 0.00605579...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>whitney</td>\n",
       "      <td>reed</td>\n",
       "      <td>US</td>\n",
       "      <td>whitney reed</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.0016876273, 'hispanic': 0.00515399...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>leonora</td>\n",
       "      <td>camovic</td>\n",
       "      <td>US</td>\n",
       "      <td>leonora camovic</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.0365716, 'hispanic': 0.016523963, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690178</th>\n",
       "      <td>lucy</td>\n",
       "      <td>youd</td>\n",
       "      <td>UK</td>\n",
       "      <td>lucy youd</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.033374153, 'hispanic': 0.07930497,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690179</th>\n",
       "      <td>nadine</td>\n",
       "      <td>jessup</td>\n",
       "      <td>US</td>\n",
       "      <td>nadine jessup</td>\n",
       "      <td>Male</td>\n",
       "      <td>nh_black</td>\n",
       "      <td>{'asian': 0.0071938434, 'hispanic': 0.01306549...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690180</th>\n",
       "      <td>leyton</td>\n",
       "      <td>attwood</td>\n",
       "      <td>UK</td>\n",
       "      <td>leyton attwood</td>\n",
       "      <td>Male</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.004400566, 'hispanic': 0.009662661...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690181</th>\n",
       "      <td>marcus</td>\n",
       "      <td>henthorn</td>\n",
       "      <td>US</td>\n",
       "      <td>marcus henthorn</td>\n",
       "      <td>Male</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.0031183357, 'hispanic': 0.01353228...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690182</th>\n",
       "      <td>kealey</td>\n",
       "      <td>atkinson</td>\n",
       "      <td>US</td>\n",
       "      <td>kealey atkinson</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.0062454003, 'hispanic': 0.01666363...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1690183 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        firstname  lastname country          fullname pred_gender     preds  \\\n",
       "0         sabouni     manal      FR     sabouni manal        Male  nh_black   \n",
       "1         claudia  perretta      UK  claudia perretta      Female  nh_white   \n",
       "2            tina     mccoy      US        tina mccoy      Female  nh_white   \n",
       "3         whitney      reed      US      whitney reed      Female  nh_white   \n",
       "4         leonora   camovic      US   leonora camovic      Female  nh_white   \n",
       "...           ...       ...     ...               ...         ...       ...   \n",
       "1690178      lucy      youd      UK         lucy youd      Female  nh_white   \n",
       "1690179    nadine    jessup      US     nadine jessup        Male  nh_black   \n",
       "1690180    leyton   attwood      UK    leyton attwood        Male  nh_white   \n",
       "1690181    marcus  henthorn      US   marcus henthorn        Male  nh_white   \n",
       "1690182    kealey  atkinson      US   kealey atkinson      Female  nh_white   \n",
       "\n",
       "                                                     probs  \n",
       "0        {'asian': 0.090085596, 'hispanic': 0.011093363...  \n",
       "1        {'asian': 0.0024087005, 'hispanic': 0.23162283...  \n",
       "2        {'asian': 0.0040824614, 'hispanic': 0.00605579...  \n",
       "3        {'asian': 0.0016876273, 'hispanic': 0.00515399...  \n",
       "4        {'asian': 0.0365716, 'hispanic': 0.016523963, ...  \n",
       "...                                                    ...  \n",
       "1690178  {'asian': 0.033374153, 'hispanic': 0.07930497,...  \n",
       "1690179  {'asian': 0.0071938434, 'hispanic': 0.01306549...  \n",
       "1690180  {'asian': 0.004400566, 'hispanic': 0.009662661...  \n",
       "1690181  {'asian': 0.0031183357, 'hispanic': 0.01353228...  \n",
       "1690182  {'asian': 0.0062454003, 'hispanic': 0.01666363...  \n",
       "\n",
       "[1690183 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_gender_full_others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>country</th>\n",
       "      <th>fullname</th>\n",
       "      <th>pred_gender</th>\n",
       "      <th>preds</th>\n",
       "      <th>probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sabouni</td>\n",
       "      <td>manal</td>\n",
       "      <td>FR</td>\n",
       "      <td>sabouni manal</td>\n",
       "      <td>Male</td>\n",
       "      <td>nh_black</td>\n",
       "      <td>{'asian': 0.090085596, 'hispanic': 0.011093363...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>claudia</td>\n",
       "      <td>perretta</td>\n",
       "      <td>UK</td>\n",
       "      <td>claudia perretta</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.0024087005, 'hispanic': 0.23162283...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tina</td>\n",
       "      <td>mccoy</td>\n",
       "      <td>US</td>\n",
       "      <td>tina mccoy</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.0040824614, 'hispanic': 0.00605579...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>whitney</td>\n",
       "      <td>reed</td>\n",
       "      <td>US</td>\n",
       "      <td>whitney reed</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.0016876273, 'hispanic': 0.00515399...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>leonora</td>\n",
       "      <td>camovic</td>\n",
       "      <td>US</td>\n",
       "      <td>leonora camovic</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.0365716, 'hispanic': 0.016523963, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690178</th>\n",
       "      <td>lucy</td>\n",
       "      <td>youd</td>\n",
       "      <td>UK</td>\n",
       "      <td>lucy youd</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.033374153, 'hispanic': 0.07930497,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690179</th>\n",
       "      <td>nadine</td>\n",
       "      <td>jessup</td>\n",
       "      <td>US</td>\n",
       "      <td>nadine jessup</td>\n",
       "      <td>Male</td>\n",
       "      <td>nh_black</td>\n",
       "      <td>{'asian': 0.0071938434, 'hispanic': 0.01306549...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690180</th>\n",
       "      <td>leyton</td>\n",
       "      <td>attwood</td>\n",
       "      <td>UK</td>\n",
       "      <td>leyton attwood</td>\n",
       "      <td>Male</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.004400566, 'hispanic': 0.009662661...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690181</th>\n",
       "      <td>marcus</td>\n",
       "      <td>henthorn</td>\n",
       "      <td>US</td>\n",
       "      <td>marcus henthorn</td>\n",
       "      <td>Male</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.0031183357, 'hispanic': 0.01353228...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690182</th>\n",
       "      <td>kealey</td>\n",
       "      <td>atkinson</td>\n",
       "      <td>US</td>\n",
       "      <td>kealey atkinson</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.0062454003, 'hispanic': 0.01666363...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1646815 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        firstname  lastname country          fullname pred_gender     preds  \\\n",
       "0         sabouni     manal      FR     sabouni manal        Male  nh_black   \n",
       "1         claudia  perretta      UK  claudia perretta      Female  nh_white   \n",
       "2            tina     mccoy      US        tina mccoy      Female  nh_white   \n",
       "3         whitney      reed      US      whitney reed      Female  nh_white   \n",
       "4         leonora   camovic      US   leonora camovic      Female  nh_white   \n",
       "...           ...       ...     ...               ...         ...       ...   \n",
       "1690178      lucy      youd      UK         lucy youd      Female  nh_white   \n",
       "1690179    nadine    jessup      US     nadine jessup        Male  nh_black   \n",
       "1690180    leyton   attwood      UK    leyton attwood        Male  nh_white   \n",
       "1690181    marcus  henthorn      US   marcus henthorn        Male  nh_white   \n",
       "1690182    kealey  atkinson      US   kealey atkinson      Female  nh_white   \n",
       "\n",
       "                                                     probs  \n",
       "0        {'asian': 0.090085596, 'hispanic': 0.011093363...  \n",
       "1        {'asian': 0.0024087005, 'hispanic': 0.23162283...  \n",
       "2        {'asian': 0.0040824614, 'hispanic': 0.00605579...  \n",
       "3        {'asian': 0.0016876273, 'hispanic': 0.00515399...  \n",
       "4        {'asian': 0.0365716, 'hispanic': 0.016523963, ...  \n",
       "...                                                    ...  \n",
       "1690178  {'asian': 0.033374153, 'hispanic': 0.07930497,...  \n",
       "1690179  {'asian': 0.0071938434, 'hispanic': 0.01306549...  \n",
       "1690180  {'asian': 0.004400566, 'hispanic': 0.009662661...  \n",
       "1690181  {'asian': 0.0031183357, 'hispanic': 0.01353228...  \n",
       "1690182  {'asian': 0.0062454003, 'hispanic': 0.01666363...  \n",
       "\n",
       "[1646815 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_gender_full_others = race_gender_full_others.dropna()\n",
    "race_gender_full_others = race_gender_full_others.drop_duplicates()\n",
    "race_gender_full_others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>country</th>\n",
       "      <th>fullname</th>\n",
       "      <th>pred_gender</th>\n",
       "      <th>preds</th>\n",
       "      <th>probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yass</td>\n",
       "      <td>yass</td>\n",
       "      <td>CA</td>\n",
       "      <td>yass</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.039757933, 'hispanic': 0.39860517,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zak</td>\n",
       "      <td>zak</td>\n",
       "      <td>UK</td>\n",
       "      <td>zak</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.022933554, 'hispanic': 0.020127507...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alyssa</td>\n",
       "      <td>alyssa</td>\n",
       "      <td>US</td>\n",
       "      <td>alyssa</td>\n",
       "      <td>Male</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.029911637, 'hispanic': 0.1969176, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kyra</td>\n",
       "      <td>kyra</td>\n",
       "      <td>UK</td>\n",
       "      <td>kyra</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.029823758, 'hispanic': 0.016653847...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>aftondivver</td>\n",
       "      <td>aftondivver</td>\n",
       "      <td>US</td>\n",
       "      <td>aftondivver</td>\n",
       "      <td>Male</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.015394655, 'hispanic': 0.040740304...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690178</th>\n",
       "      <td>lucy</td>\n",
       "      <td>youd</td>\n",
       "      <td>UK</td>\n",
       "      <td>lucy youd</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.033374153, 'hispanic': 0.07930497,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690179</th>\n",
       "      <td>nadine</td>\n",
       "      <td>jessup</td>\n",
       "      <td>US</td>\n",
       "      <td>nadine jessup</td>\n",
       "      <td>Male</td>\n",
       "      <td>nh_black</td>\n",
       "      <td>{'asian': 0.0071938434, 'hispanic': 0.01306549...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690180</th>\n",
       "      <td>leyton</td>\n",
       "      <td>attwood</td>\n",
       "      <td>UK</td>\n",
       "      <td>leyton attwood</td>\n",
       "      <td>Male</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.004400566, 'hispanic': 0.009662661...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690181</th>\n",
       "      <td>marcus</td>\n",
       "      <td>henthorn</td>\n",
       "      <td>US</td>\n",
       "      <td>marcus henthorn</td>\n",
       "      <td>Male</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.0031183357, 'hispanic': 0.01353228...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690182</th>\n",
       "      <td>kealey</td>\n",
       "      <td>atkinson</td>\n",
       "      <td>US</td>\n",
       "      <td>kealey atkinson</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.0062454003, 'hispanic': 0.01666363...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1712802 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           firstname     lastname country         fullname pred_gender  \\\n",
       "0               yass         yass      CA             yass      Female   \n",
       "1                zak          zak      UK              zak      Female   \n",
       "4             alyssa       alyssa      US           alyssa        Male   \n",
       "6               kyra         kyra      UK             kyra      Female   \n",
       "10       aftondivver  aftondivver      US      aftondivver        Male   \n",
       "...              ...          ...     ...              ...         ...   \n",
       "1690178         lucy         youd      UK        lucy youd      Female   \n",
       "1690179       nadine       jessup      US    nadine jessup        Male   \n",
       "1690180       leyton      attwood      UK   leyton attwood        Male   \n",
       "1690181       marcus     henthorn      US  marcus henthorn        Male   \n",
       "1690182       kealey     atkinson      US  kealey atkinson      Female   \n",
       "\n",
       "            preds                                              probs  \n",
       "0        nh_white  {'asian': 0.039757933, 'hispanic': 0.39860517,...  \n",
       "1        nh_white  {'asian': 0.022933554, 'hispanic': 0.020127507...  \n",
       "4        nh_white  {'asian': 0.029911637, 'hispanic': 0.1969176, ...  \n",
       "6        nh_white  {'asian': 0.029823758, 'hispanic': 0.016653847...  \n",
       "10       nh_white  {'asian': 0.015394655, 'hispanic': 0.040740304...  \n",
       "...           ...                                                ...  \n",
       "1690178  nh_white  {'asian': 0.033374153, 'hispanic': 0.07930497,...  \n",
       "1690179  nh_black  {'asian': 0.0071938434, 'hispanic': 0.01306549...  \n",
       "1690180  nh_white  {'asian': 0.004400566, 'hispanic': 0.009662661...  \n",
       "1690181  nh_white  {'asian': 0.0031183357, 'hispanic': 0.01353228...  \n",
       "1690182  nh_white  {'asian': 0.0062454003, 'hispanic': 0.01666363...  \n",
       "\n",
       "[1712802 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.concat([race_gender_last_single, race_gender_full_others], axis=0)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"./username_gender_race.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>country</th>\n",
       "      <th>fullname</th>\n",
       "      <th>pred_gender</th>\n",
       "      <th>preds</th>\n",
       "      <th>probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>yass</td>\n",
       "      <td>yass</td>\n",
       "      <td>CA</td>\n",
       "      <td>yass</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.039757933, 'hispanic': 0.39860517,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>zak</td>\n",
       "      <td>zak</td>\n",
       "      <td>UK</td>\n",
       "      <td>zak</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.022933554, 'hispanic': 0.020127507...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>alyssa</td>\n",
       "      <td>alyssa</td>\n",
       "      <td>US</td>\n",
       "      <td>alyssa</td>\n",
       "      <td>Male</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.029911637, 'hispanic': 0.1969176, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>kyra</td>\n",
       "      <td>kyra</td>\n",
       "      <td>UK</td>\n",
       "      <td>kyra</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.029823758, 'hispanic': 0.016653847...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>aftondivver</td>\n",
       "      <td>aftondivver</td>\n",
       "      <td>US</td>\n",
       "      <td>aftondivver</td>\n",
       "      <td>Male</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.015394655, 'hispanic': 0.040740304...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712797</th>\n",
       "      <td>1690178</td>\n",
       "      <td>lucy</td>\n",
       "      <td>youd</td>\n",
       "      <td>UK</td>\n",
       "      <td>lucy youd</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.033374153, 'hispanic': 0.07930497,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712798</th>\n",
       "      <td>1690179</td>\n",
       "      <td>nadine</td>\n",
       "      <td>jessup</td>\n",
       "      <td>US</td>\n",
       "      <td>nadine jessup</td>\n",
       "      <td>Male</td>\n",
       "      <td>nh_black</td>\n",
       "      <td>{'asian': 0.0071938434, 'hispanic': 0.01306549...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712799</th>\n",
       "      <td>1690180</td>\n",
       "      <td>leyton</td>\n",
       "      <td>attwood</td>\n",
       "      <td>UK</td>\n",
       "      <td>leyton attwood</td>\n",
       "      <td>Male</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.004400566, 'hispanic': 0.009662661...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712800</th>\n",
       "      <td>1690181</td>\n",
       "      <td>marcus</td>\n",
       "      <td>henthorn</td>\n",
       "      <td>US</td>\n",
       "      <td>marcus henthorn</td>\n",
       "      <td>Male</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.0031183357, 'hispanic': 0.01353228...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712801</th>\n",
       "      <td>1690182</td>\n",
       "      <td>kealey</td>\n",
       "      <td>atkinson</td>\n",
       "      <td>US</td>\n",
       "      <td>kealey atkinson</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>{'asian': 0.0062454003, 'hispanic': 0.01666363...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1712802 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0    firstname     lastname country         fullname  \\\n",
       "0                 0         yass         yass      CA             yass   \n",
       "1                 1          zak          zak      UK              zak   \n",
       "2                 4       alyssa       alyssa      US           alyssa   \n",
       "3                 6         kyra         kyra      UK             kyra   \n",
       "4                10  aftondivver  aftondivver      US      aftondivver   \n",
       "...             ...          ...          ...     ...              ...   \n",
       "1712797     1690178         lucy         youd      UK        lucy youd   \n",
       "1712798     1690179       nadine       jessup      US    nadine jessup   \n",
       "1712799     1690180       leyton      attwood      UK   leyton attwood   \n",
       "1712800     1690181       marcus     henthorn      US  marcus henthorn   \n",
       "1712801     1690182       kealey     atkinson      US  kealey atkinson   \n",
       "\n",
       "        pred_gender     preds  \\\n",
       "0            Female  nh_white   \n",
       "1            Female  nh_white   \n",
       "2              Male  nh_white   \n",
       "3            Female  nh_white   \n",
       "4              Male  nh_white   \n",
       "...             ...       ...   \n",
       "1712797      Female  nh_white   \n",
       "1712798        Male  nh_black   \n",
       "1712799        Male  nh_white   \n",
       "1712800        Male  nh_white   \n",
       "1712801      Female  nh_white   \n",
       "\n",
       "                                                     probs  \n",
       "0        {'asian': 0.039757933, 'hispanic': 0.39860517,...  \n",
       "1        {'asian': 0.022933554, 'hispanic': 0.020127507...  \n",
       "2        {'asian': 0.029911637, 'hispanic': 0.1969176, ...  \n",
       "3        {'asian': 0.029823758, 'hispanic': 0.016653847...  \n",
       "4        {'asian': 0.015394655, 'hispanic': 0.040740304...  \n",
       "...                                                    ...  \n",
       "1712797  {'asian': 0.033374153, 'hispanic': 0.07930497,...  \n",
       "1712798  {'asian': 0.0071938434, 'hispanic': 0.01306549...  \n",
       "1712799  {'asian': 0.004400566, 'hispanic': 0.009662661...  \n",
       "1712800  {'asian': 0.0031183357, 'hispanic': 0.01353228...  \n",
       "1712801  {'asian': 0.0062454003, 'hispanic': 0.01666363...  \n",
       "\n",
       "[1712802 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"username_gender_race.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
